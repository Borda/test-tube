{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Test Tube: Easily log and tune Deep Learning experiments Test Tube allows you to easily log metadata and track your machine learning experiments. Use Test Tube if you need to: Track many Experiments across models. Visualize and compare different experiments without uploading anywhere. Optimize your hyperparameters using grid search or random search. Automatically track ALL parameters for a particular training run. Test Tube is compatible with: Python 2 and 3 Getting started Create an Experiment from test_tube import Experiment exp = Experiment(name='dense_model', debug=False, save_dir='/Desktop/test_tube') exp.tag({'learning_rate': 0.002, 'nb_layers': 2}) for step in training_steps: tng_err = model.eval(tng_x, tng_y) exp.log('tng_err': tng_err) # training complete! # all your logs and data are ready to be visualized at testtube.williamfalcon.com Optimize your hyperparameters from test_tube import HyperOptArgumentParser # subclass of argparse parser = HyperOptArgumentParser(strategy='random_search') parser.add_argument('--learning_rate', default=0.002, type=float, help='the learning rate') # let's enable optimizing over the number of layers in the network parser.opt_list('--nb_layers', default=2, type=int, tunable=True, options=[2, 4, 8]) # and tune the number of units in each layer parser.opt_range('--neurons', default=50, type=int, tunable=True, low=100, high=800, nb_samples=10) # compile (because it's argparse underneath) hparams = parser.parse_args() # run 20 trials of random search over the hyperparams for hparam_trial in hparams.trials(20): train_network(hparam_trial) Visualize import pandas as pd import matplotlib # each experiment is saved to a metrics.csv file which can be imported anywhere # images save to exp/version/images df = pd.read_csv('../some/dir/test_tube_data/dense_model/version_0/metrics.csv') df.tng_err.plot()","title":"Test Tube: Easily log and tune Deep Learning experiments"},{"location":"#test-tube-easily-log-and-tune-deep-learning-experiments","text":"Test Tube allows you to easily log metadata and track your machine learning experiments. Use Test Tube if you need to: Track many Experiments across models. Visualize and compare different experiments without uploading anywhere. Optimize your hyperparameters using grid search or random search. Automatically track ALL parameters for a particular training run. Test Tube is compatible with: Python 2 and 3","title":"Test Tube: Easily log and tune Deep Learning experiments"},{"location":"#getting-started","text":"","title":"Getting started"},{"location":"#create-an-experiment","text":"from test_tube import Experiment exp = Experiment(name='dense_model', debug=False, save_dir='/Desktop/test_tube') exp.tag({'learning_rate': 0.002, 'nb_layers': 2}) for step in training_steps: tng_err = model.eval(tng_x, tng_y) exp.log('tng_err': tng_err) # training complete! # all your logs and data are ready to be visualized at testtube.williamfalcon.com","title":"Create an Experiment"},{"location":"#optimize-your-hyperparameters","text":"from test_tube import HyperOptArgumentParser # subclass of argparse parser = HyperOptArgumentParser(strategy='random_search') parser.add_argument('--learning_rate', default=0.002, type=float, help='the learning rate') # let's enable optimizing over the number of layers in the network parser.opt_list('--nb_layers', default=2, type=int, tunable=True, options=[2, 4, 8]) # and tune the number of units in each layer parser.opt_range('--neurons', default=50, type=int, tunable=True, low=100, high=800, nb_samples=10) # compile (because it's argparse underneath) hparams = parser.parse_args() # run 20 trials of random search over the hyperparams for hparam_trial in hparams.trials(20): train_network(hparam_trial)","title":"Optimize your hyperparameters"},{"location":"#visualize","text":"import pandas as pd import matplotlib # each experiment is saved to a metrics.csv file which can be imported anywhere # images save to exp/version/images df = pd.read_csv('../some/dir/test_tube_data/dense_model/version_0/metrics.csv') df.tng_err.plot()","title":"Visualize"},{"location":"experiment_tracking/experiment/","text":"Experiment class API An Experiment holds metadata and the results of the training run, you can instantiate an Experiment via: from test_tube import Experiment exp = Experiment(name='dense_model', debug=False, save_dir='/Desktop/test_tube') exp.tag({'learning_rate': 0.002, 'nb_layers': 2}) for step in training_steps: tng_err = model.eval(tng_x, tng_y) exp.log('tng_err': tng_err) # training complete! # all your logs and data are ready to be visualized at testtube.williamfalcon.com init options version The same Experiment can have multiple versions. Test tube generates these automatically each time you run your model. To set your own version use: exp = Experiment(name='dense_model',version=1) debug If you're debugging and don't want to create a log file turn debug to True exp = Experiment(name='dense_model',debug=True) autosave If you only want to save at the end of training, turn autosave off: exp = Experiment(name='dense_model', autosave=False) # run long training... # first time any logs are saved exp.save() create_git_tag Ever wanted a flashback to your code when you ran an experiment? Snapshot your code for this experiment using git tags: exp = Experiment(name='dense_model', create_git_tag=True) Methods tag exp.tag({k: v}) Adds an arbitrary dictionary of tags to the experiment Example exp.tag({'dataset_name': 'imagenet_1', 'learning_rate': 0.0002}) log exp.log({k:v}) Adds a row of data to the experiments Example exp.log({'val_loss': 0.22, 'epoch_nb': 1, 'batch_nb': 12}) # you can also add other rows that have separate information exp.log({'tng_loss': 0.01}) # or even a numpy array image image = np.imread('image.png') exp.log({'fake_png': image}) Saving images Example # name must have either jpg, png or jpeg in it img = np.imread('a.jpg') exp.log('test_jpg': img, 'val_err': 0.2) # saves image to ../exp/version/media/test_0.jpg # csv has file path to that image in that cell To save an image, add jpg , png or jpeg to the key corresponding with the image array. The image must be formatted the same as skimage's imsave function argparse exp.argparse(hparams) Transfers hyperparam information from Argparser or HyperOptArgumentParser Example from test_tube import HyperOptArgumentParser # parse args parser = HyperOptArgumentParser() parser.add_argument('--learning_rate', default=0.002, type=float, help='the learning rate') hparams = parser.parse_args() # learning_rate is now a meta tag for your experiment exp.argparse(hparams) save exp.save() Saves the exp to disk (including images) Example exp = Experiment(name='dense_model', autosave=False) # run long training... # first time any logs are saved exp.save()","title":"Experiment class API"},{"location":"experiment_tracking/experiment/#experiment-class-api","text":"An Experiment holds metadata and the results of the training run, you can instantiate an Experiment via: from test_tube import Experiment exp = Experiment(name='dense_model', debug=False, save_dir='/Desktop/test_tube') exp.tag({'learning_rate': 0.002, 'nb_layers': 2}) for step in training_steps: tng_err = model.eval(tng_x, tng_y) exp.log('tng_err': tng_err) # training complete! # all your logs and data are ready to be visualized at testtube.williamfalcon.com","title":"Experiment class API"},{"location":"experiment_tracking/experiment/#init-options","text":"","title":"init options"},{"location":"experiment_tracking/experiment/#version","text":"The same Experiment can have multiple versions. Test tube generates these automatically each time you run your model. To set your own version use: exp = Experiment(name='dense_model',version=1)","title":"version"},{"location":"experiment_tracking/experiment/#debug","text":"If you're debugging and don't want to create a log file turn debug to True exp = Experiment(name='dense_model',debug=True)","title":"debug"},{"location":"experiment_tracking/experiment/#autosave","text":"If you only want to save at the end of training, turn autosave off: exp = Experiment(name='dense_model', autosave=False) # run long training... # first time any logs are saved exp.save()","title":"autosave"},{"location":"experiment_tracking/experiment/#create_git_tag","text":"Ever wanted a flashback to your code when you ran an experiment? Snapshot your code for this experiment using git tags: exp = Experiment(name='dense_model', create_git_tag=True)","title":"create_git_tag"},{"location":"experiment_tracking/experiment/#methods","text":"","title":"Methods"},{"location":"experiment_tracking/experiment/#tag","text":"exp.tag({k: v}) Adds an arbitrary dictionary of tags to the experiment Example exp.tag({'dataset_name': 'imagenet_1', 'learning_rate': 0.0002})","title":"tag"},{"location":"experiment_tracking/experiment/#log","text":"exp.log({k:v}) Adds a row of data to the experiments Example exp.log({'val_loss': 0.22, 'epoch_nb': 1, 'batch_nb': 12}) # you can also add other rows that have separate information exp.log({'tng_loss': 0.01}) # or even a numpy array image image = np.imread('image.png') exp.log({'fake_png': image}) Saving images Example # name must have either jpg, png or jpeg in it img = np.imread('a.jpg') exp.log('test_jpg': img, 'val_err': 0.2) # saves image to ../exp/version/media/test_0.jpg # csv has file path to that image in that cell To save an image, add jpg , png or jpeg to the key corresponding with the image array. The image must be formatted the same as skimage's imsave function","title":"log"},{"location":"experiment_tracking/experiment/#argparse","text":"exp.argparse(hparams) Transfers hyperparam information from Argparser or HyperOptArgumentParser Example from test_tube import HyperOptArgumentParser # parse args parser = HyperOptArgumentParser() parser.add_argument('--learning_rate', default=0.002, type=float, help='the learning rate') hparams = parser.parse_args() # learning_rate is now a meta tag for your experiment exp.argparse(hparams)","title":"argparse"},{"location":"experiment_tracking/experiment/#save","text":"exp.save() Saves the exp to disk (including images) Example exp = Experiment(name='dense_model', autosave=False) # run long training... # first time any logs are saved exp.save()","title":"save"},{"location":"hpc/SlurmCluster/","text":"SlurmCluster class API The SlurmCluster class enables hyperparameter search parallelization on a cluster managed via Slurm workload manager . At a high level, the SlurmCluster creates a submit script for each permutation of hyperparameters requested. If the job hits the walltime but has not completed, the SlurmManager will checkpoint the model and submit a new job to continue training using the saved weights. You can instantiate a SlurmCluster via: from test_tube.hpc import SlurmCluster # hyperparameters is a test-tube hyper params object # see https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/ hyperparams = args.parse() # init cluster cluster = SlurmCluster( hyperparam_optimizer=hyperparams, log_path='/path/to/log/results/to', python_cmd='python3' ) # let the cluster know where to email for a change in job status (ie: complete, fail, etc...) cluster.notify_job_status(email='some@email.com', on_done=True, on_fail=True) # set the job options. In this instance, we'll run 20 different models # each with its own set of hyperparameters giving each one 1 GPU (ie: taking up 20 GPUs) cluster.per_experiment_nb_gpus = 1 cluster.per_experiment_nb_nodes = 1 # we'll request 10GB of memory per node cluster.memory_mb_per_node = 10000 # set a walltime of 10 minues cluster.job_time = '10:00' # 1 minute before walltime is up, SlurmCluster will launch a continuation job and kill this job. # you must provide your own loading and saving function which the cluster object will call cluster.minutes_to_checkpoint_before_walltime = 1 # run the models on the cluster cluster.optimize_parallel_cluster_gpu(train, nb_trials=20, job_name='first_tt_batch', job_display_name='my_batch') init options hyperparam_optimizer A HyperOptArgumentParser object which contains all permutations of model hyperparameters to run. log_path Path to save the slurm scripts, error logs and out logs created. Usually this would be the experiments folder path where test tube saves Experiment information. python_cmd This is the command that starts the python program. Normally it is: # python 2 python main.py # python 3 python3 main.py enable_log_err If true, saves slurm error logs to the path at log_path . If anything goes wrong in your job, you'll find the error here. enable_log_out If true, saves slurm output logs to the path at log_path . This file contains all outputs that would show up on the console normally. test_tube_exp_name When this is given, it structures the files in a nice format to fit with the folder structure of the Experiment object's output. Methods Properties job_time String. Walltime requested. Examples: # 1 hour and 10 minutes cluster.job_time = '1:10:00' # 1 day and 1 hour and 10 minutes cluster.job_time = '1-1:10:00' # 1 day and 1 hour and 10 minutes cluster.job_time = '25:10:00' # 10 minutes cluster.job_time = '10:00' # 10 seconds cluster.job_time = '10' minutes_to_checkpoint_before_walltime Int. Minutes before walltime when a continuation job will be auto-submitted. cluster.job_time = '10:00' cluster.minutes_to_checkpoint_before_walltime = 2 # New job will be submited to continue training after 8 minutes of the job running. per_experiment_nb_gpus Int. Number of GPUs each job will get. # EACH job will get 2 GPUs (ie: if a model runs over two GPUs at the same time). cluster.per_experiment_nb_gpus = 2 per_experiment_nb_cpus Int. Number of CPUs each job will get. cluster.per_experiment_nb_cpus = 1 per_experiment_nb_nodes Int. Number of nodes each job will get. cluster.per_experiment_nb_nodes = 1 gpu_type String. Gpu type requested. Example: cluster.gpu_type = '1080ti' Methods set_checkpoint_save_function cluster.set_checkpoint_save_function(fx, kwargs) Called if the model isn't finished training minutes_to_checkpoint_before_walltime before the walltime. If walltime = '15:00' and minutes_to_checkpoint_before_walltime = '1:00' the SlurmCluster will call your save function after 14 minutes of training. fx A python function. kwargs Dictionary where keys are the literal argument names to the function. Dictionary values are the values of the arguments. Example def my_save_function(arg_1, arg_k): # ... save my model here cluster.set_checkpoint_save_function(my_save_function, kwargs={'arg_1': 'whatever', 'arg_k': 'you_want'}) set_checkpoint_load_function cluster.set_checkpoint_load_function(fx, kwargs) Called internally when a job is auto-submitted by the SlurmCluster to give your program a chance to load the model weights or whatever you need to continue training. This will call your load function immediately whenever you call this method AND training is continuing. fx A python function. kwargs Dictionary where keys are the literal argument names to the function. Dictionary values are the values of the arguments. Example def my_load_function(arg_1, arg_k): # ... restore my model here cluster.set_checkpoint_save_function(my_load_function, kwargs={'arg_1': 'whatever', 'arg_k': 'you_want'}) add_slurm_cmd cluster.add_slurm_cmd(cmd, value, comment) Adds whatever Slurm command you need manually to the generated script. All possible commands are listed here . cmd String with the bash command. value String value for the command. Numericals need to be in single quotes '1' comment String with the command comment. Example cluster.add_slurm_cmd(cmd='cpus-per-task', value='1', comment='nb cpus per task') # the above command will add an entry like this to the slurm script # #nb cpus per task # #SBATCH --cpus-per-task=1 # ############ add_command cluster.add_command(cmd) Adds arbitrary bash commands to the script. Use this to activate conda environments, install packages, whatever else you would think about calling on bash. cmd String with your bash command. Example # load the anaconda package on the launch node cluster.add_command('module load anaconda') # activate the environment on the launch node cluster.add_command('source activate myCondaEnv') load_modules cluster.load_modules(modules) Loads modules needed to run the job. Your Slurm documentation should have a list of available modules. You can also get those by running module avail . - modules Array of module names. Example cluster.load_modules([ 'python-3', 'anaconda3' ]) notify_job_status cluster.notify_job_status(email, on_done, on_fail) Loads modules needed to run the job. Your Slurm documentation should have a list of available modules. You can also get those by running module avail . email String. Email address to get notifications. on_done Boolean. If true, you'll get an email when the job completes. on_fail Boolean. If true, you'll get an email if the job fails. Example cluster.notify_job_status(email='some@email.com', on_done=True, on_fail=True) optimize_parallel_cluster_gpu cluster.optimize_parallel_cluster_gpu(train_function, nb_trials, job_name, job_display_name=None) Launches the hyperparameter search across the cluster nodes. - train_function The entry point to start your training routine. - nb_trials Number of trials to launch. This is the number of hyperparameter configurations to train over. - job_name Folder name where the slurm scripts will save to. This should be the same as your Experiment name. - job_display_name Visible name when slurm lists running jobs (ie: through squeue -u user_name ). This should be really short (if using a test tube Experiment, it'll put the experiment version at the end). Example def main(hparams, cluster, return_dict): # do your own generic training code here... # init model model = model_build(hparams) # set the load and save fxs cluster.set_checkpoint_save_function(fx, {}) cluster.set_checkpoint_load_function(fx, {}) # train ... cluster.optimize_parallel_cluster_gpu(main, nb_trials=20, job_name='my_job', job_display_name='mj') Now if you get the job information, you'll see this: (conda_env) [user@node dir]$ squeue -u my_name JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 104040 all mjv0 my_name R 58:22 1 nodeName 104041 all mjv1 my_name R 58:22 1 nodeName 104042 all mjv2 my_name R 58:22 1 nodeName 104043 all mjv3 my_name R 58:22 1 nodeName optimize_parallel_cluster_cpu cluster.optimize_parallel_cluster_cpu(train_function, nb_trials, job_name, job_display_name=None) Launches the hyperparameter search across the cluster nodes using cpus. - train_function The entry point to start your training routine. - nb_trials Number of trials to launch. This is the number of hyperparameter configurations to train over. - job_name Folder name where the slurm scripts will save to. This should be the same as your Experiment name. - job_display_name Visible name when slurm lists running jobs (ie: through squeue -u user_name ). This should be really short (if using a test tube Experiment, it'll put the experiment version at the end). Example def main(hparams, cluster, return_dict): # do your own generic training code here... # init model model = model_build(hparams) # set the load and save fxs cluster.set_checkpoint_save_function(fx, {}) cluster.set_checkpoint_load_function(fx, {}) # train ... cluster.optimize_parallel_cluster_cpu(main, nb_trials=20, job_name='my_job', job_display_name='mj') Now if you get the job information, you'll see this: (conda_env) [user@node dir]$ squeue -u my_name JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 104040 all mjv0 my_name R 58:22 1 nodeName 104041 all mjv1 my_name R 58:22 1 nodeName 104042 all mjv2 my_name R 58:22 1 nodeName 104043 all mjv3 my_name R 58:22 1 nodeName","title":"SlurmCluster class API"},{"location":"hpc/SlurmCluster/#slurmcluster-class-api","text":"The SlurmCluster class enables hyperparameter search parallelization on a cluster managed via Slurm workload manager . At a high level, the SlurmCluster creates a submit script for each permutation of hyperparameters requested. If the job hits the walltime but has not completed, the SlurmManager will checkpoint the model and submit a new job to continue training using the saved weights. You can instantiate a SlurmCluster via: from test_tube.hpc import SlurmCluster # hyperparameters is a test-tube hyper params object # see https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/ hyperparams = args.parse() # init cluster cluster = SlurmCluster( hyperparam_optimizer=hyperparams, log_path='/path/to/log/results/to', python_cmd='python3' ) # let the cluster know where to email for a change in job status (ie: complete, fail, etc...) cluster.notify_job_status(email='some@email.com', on_done=True, on_fail=True) # set the job options. In this instance, we'll run 20 different models # each with its own set of hyperparameters giving each one 1 GPU (ie: taking up 20 GPUs) cluster.per_experiment_nb_gpus = 1 cluster.per_experiment_nb_nodes = 1 # we'll request 10GB of memory per node cluster.memory_mb_per_node = 10000 # set a walltime of 10 minues cluster.job_time = '10:00' # 1 minute before walltime is up, SlurmCluster will launch a continuation job and kill this job. # you must provide your own loading and saving function which the cluster object will call cluster.minutes_to_checkpoint_before_walltime = 1 # run the models on the cluster cluster.optimize_parallel_cluster_gpu(train, nb_trials=20, job_name='first_tt_batch', job_display_name='my_batch')","title":"SlurmCluster class API"},{"location":"hpc/SlurmCluster/#init-options","text":"","title":"init options"},{"location":"hpc/SlurmCluster/#hyperparam_optimizer","text":"A HyperOptArgumentParser object which contains all permutations of model hyperparameters to run.","title":"hyperparam_optimizer"},{"location":"hpc/SlurmCluster/#log_path","text":"Path to save the slurm scripts, error logs and out logs created. Usually this would be the experiments folder path where test tube saves Experiment information.","title":"log_path"},{"location":"hpc/SlurmCluster/#python_cmd","text":"This is the command that starts the python program. Normally it is: # python 2 python main.py # python 3 python3 main.py","title":"python_cmd"},{"location":"hpc/SlurmCluster/#enable_log_err","text":"If true, saves slurm error logs to the path at log_path . If anything goes wrong in your job, you'll find the error here.","title":"enable_log_err"},{"location":"hpc/SlurmCluster/#enable_log_out","text":"If true, saves slurm output logs to the path at log_path . This file contains all outputs that would show up on the console normally.","title":"enable_log_out"},{"location":"hpc/SlurmCluster/#test_tube_exp_name","text":"When this is given, it structures the files in a nice format to fit with the folder structure of the Experiment object's output.","title":"test_tube_exp_name"},{"location":"hpc/SlurmCluster/#methods","text":"Properties job_time String. Walltime requested. Examples: # 1 hour and 10 minutes cluster.job_time = '1:10:00' # 1 day and 1 hour and 10 minutes cluster.job_time = '1-1:10:00' # 1 day and 1 hour and 10 minutes cluster.job_time = '25:10:00' # 10 minutes cluster.job_time = '10:00' # 10 seconds cluster.job_time = '10' minutes_to_checkpoint_before_walltime Int. Minutes before walltime when a continuation job will be auto-submitted. cluster.job_time = '10:00' cluster.minutes_to_checkpoint_before_walltime = 2 # New job will be submited to continue training after 8 minutes of the job running. per_experiment_nb_gpus Int. Number of GPUs each job will get. # EACH job will get 2 GPUs (ie: if a model runs over two GPUs at the same time). cluster.per_experiment_nb_gpus = 2 per_experiment_nb_cpus Int. Number of CPUs each job will get. cluster.per_experiment_nb_cpus = 1 per_experiment_nb_nodes Int. Number of nodes each job will get. cluster.per_experiment_nb_nodes = 1 gpu_type String. Gpu type requested. Example: cluster.gpu_type = '1080ti'","title":"Methods"},{"location":"hpc/SlurmCluster/#methods_1","text":"","title":"Methods"},{"location":"hpc/SlurmCluster/#set_checkpoint_save_function","text":"cluster.set_checkpoint_save_function(fx, kwargs) Called if the model isn't finished training minutes_to_checkpoint_before_walltime before the walltime. If walltime = '15:00' and minutes_to_checkpoint_before_walltime = '1:00' the SlurmCluster will call your save function after 14 minutes of training. fx A python function. kwargs Dictionary where keys are the literal argument names to the function. Dictionary values are the values of the arguments. Example def my_save_function(arg_1, arg_k): # ... save my model here cluster.set_checkpoint_save_function(my_save_function, kwargs={'arg_1': 'whatever', 'arg_k': 'you_want'})","title":"set_checkpoint_save_function"},{"location":"hpc/SlurmCluster/#set_checkpoint_load_function","text":"cluster.set_checkpoint_load_function(fx, kwargs) Called internally when a job is auto-submitted by the SlurmCluster to give your program a chance to load the model weights or whatever you need to continue training. This will call your load function immediately whenever you call this method AND training is continuing. fx A python function. kwargs Dictionary where keys are the literal argument names to the function. Dictionary values are the values of the arguments. Example def my_load_function(arg_1, arg_k): # ... restore my model here cluster.set_checkpoint_save_function(my_load_function, kwargs={'arg_1': 'whatever', 'arg_k': 'you_want'})","title":"set_checkpoint_load_function"},{"location":"hpc/SlurmCluster/#add_slurm_cmd","text":"cluster.add_slurm_cmd(cmd, value, comment) Adds whatever Slurm command you need manually to the generated script. All possible commands are listed here . cmd String with the bash command. value String value for the command. Numericals need to be in single quotes '1' comment String with the command comment. Example cluster.add_slurm_cmd(cmd='cpus-per-task', value='1', comment='nb cpus per task') # the above command will add an entry like this to the slurm script # #nb cpus per task # #SBATCH --cpus-per-task=1 # ############","title":"add_slurm_cmd"},{"location":"hpc/SlurmCluster/#add_command","text":"cluster.add_command(cmd) Adds arbitrary bash commands to the script. Use this to activate conda environments, install packages, whatever else you would think about calling on bash. cmd String with your bash command. Example # load the anaconda package on the launch node cluster.add_command('module load anaconda') # activate the environment on the launch node cluster.add_command('source activate myCondaEnv')","title":"add_command"},{"location":"hpc/SlurmCluster/#load_modules","text":"cluster.load_modules(modules) Loads modules needed to run the job. Your Slurm documentation should have a list of available modules. You can also get those by running module avail . - modules Array of module names. Example cluster.load_modules([ 'python-3', 'anaconda3' ])","title":"load_modules"},{"location":"hpc/SlurmCluster/#notify_job_status","text":"cluster.notify_job_status(email, on_done, on_fail) Loads modules needed to run the job. Your Slurm documentation should have a list of available modules. You can also get those by running module avail . email String. Email address to get notifications. on_done Boolean. If true, you'll get an email when the job completes. on_fail Boolean. If true, you'll get an email if the job fails. Example cluster.notify_job_status(email='some@email.com', on_done=True, on_fail=True)","title":"notify_job_status"},{"location":"hpc/SlurmCluster/#optimize_parallel_cluster_gpu","text":"cluster.optimize_parallel_cluster_gpu(train_function, nb_trials, job_name, job_display_name=None) Launches the hyperparameter search across the cluster nodes. - train_function The entry point to start your training routine. - nb_trials Number of trials to launch. This is the number of hyperparameter configurations to train over. - job_name Folder name where the slurm scripts will save to. This should be the same as your Experiment name. - job_display_name Visible name when slurm lists running jobs (ie: through squeue -u user_name ). This should be really short (if using a test tube Experiment, it'll put the experiment version at the end). Example def main(hparams, cluster, return_dict): # do your own generic training code here... # init model model = model_build(hparams) # set the load and save fxs cluster.set_checkpoint_save_function(fx, {}) cluster.set_checkpoint_load_function(fx, {}) # train ... cluster.optimize_parallel_cluster_gpu(main, nb_trials=20, job_name='my_job', job_display_name='mj') Now if you get the job information, you'll see this: (conda_env) [user@node dir]$ squeue -u my_name JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 104040 all mjv0 my_name R 58:22 1 nodeName 104041 all mjv1 my_name R 58:22 1 nodeName 104042 all mjv2 my_name R 58:22 1 nodeName 104043 all mjv3 my_name R 58:22 1 nodeName","title":"optimize_parallel_cluster_gpu"},{"location":"hpc/SlurmCluster/#optimize_parallel_cluster_cpu","text":"cluster.optimize_parallel_cluster_cpu(train_function, nb_trials, job_name, job_display_name=None) Launches the hyperparameter search across the cluster nodes using cpus. - train_function The entry point to start your training routine. - nb_trials Number of trials to launch. This is the number of hyperparameter configurations to train over. - job_name Folder name where the slurm scripts will save to. This should be the same as your Experiment name. - job_display_name Visible name when slurm lists running jobs (ie: through squeue -u user_name ). This should be really short (if using a test tube Experiment, it'll put the experiment version at the end). Example def main(hparams, cluster, return_dict): # do your own generic training code here... # init model model = model_build(hparams) # set the load and save fxs cluster.set_checkpoint_save_function(fx, {}) cluster.set_checkpoint_load_function(fx, {}) # train ... cluster.optimize_parallel_cluster_cpu(main, nb_trials=20, job_name='my_job', job_display_name='mj') Now if you get the job information, you'll see this: (conda_env) [user@node dir]$ squeue -u my_name JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 104040 all mjv0 my_name R 58:22 1 nodeName 104041 all mjv1 my_name R 58:22 1 nodeName 104042 all mjv2 my_name R 58:22 1 nodeName 104043 all mjv3 my_name R 58:22 1 nodeName","title":"optimize_parallel_cluster_cpu"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/","text":"HyperOptArgumentParser class API The HyperOptArgumentParser is a subclass of python's argparse , with added finctionality to change parameters on the fly as determined by a sampling strategy. You can instantiate an HyperOptArgumentParser via: from test_tube import HyperOptArgumentParser # subclass of argparse parser = HyperOptArgumentParser(strategy='random_search') parser.add_argument('--learning_rate', default=0.002, type=float, help='the learning rate') # let's enable optimizing over the number of layers in the network parser.opt_list('--nb_layers', default=2, type=int, tunable=True, options=[2, 4, 8]) # and tune the number of units in each layer parser.opt_range('--neurons', default=50, type=int, tunable=True, low=100, high=800, nb_samples=10) # compile (because it's argparse underneath) hparams = parser.parse_args() # run 20 trials of random search over the hyperparams for hparam_trial in hparams.trials(20): train_network(hparam_trial) init options strategy Use either random search or grid search for tuning: parser = HyperOptArgumentParser(strategy='grid_search') Methods All the functionality from argparse works but we've added the following functionality: opt_list parser.opt_list('--nb_layers', default=2, type=int, tunable=True, options=[2, 4, 8]) Enables searching over a list of values for this parameter. The tunable values ONLY replace the argparse values when running a hyperparameter optimization search. This is on purpose so your code doesn't have to change when you want to tune it. Example parser.opt_list('--nb_layers', default=2, type=int, tunable=True, options=[2, 4, 8]) hparams = parser.parse_args() # hparams.nb_layers = 2 for trial in hparams.trials(2): # trial.nb_layers is now a value in [2, 4, 8] # but hparams.nb_layers is still 2 opt_range parser.opt_range('--neurons', default=50, type=int, tunable=True, low=100, high=800, nb_samples=8, log_base=None) Enables searching over a range of values chosen randomly using the nb_samples given. The tunable values only replace the argparse values when running a hyperparameter optimization search. This is on purpose so your code doesn't have to change when you want to tune it. If log_base is set to a positive number, it will randomly search over a log scale, where the log base is log_base . This is better for search over several orders of magnitude efficiently. Example parser.opt_range('--neurons', default=50, type=int, tunable=True, low=100, high=800, nb_samples=8) hparams = parser.parse_args() # hparams.neurons = 50 for trial in hparams.trials(2): # trial.nb_layers is now a value in [100, 200, 300, 400, 500, 600 700, 800] # but hparams.neurons is still 50 json_config parser.json_config('--config', default='example.json') Replaces default values in the parser with those read from the json file Example example.json { learning_rate : 200 } parser.add_argument('--learning_rate', default=0.002, type=float, help='the learning rate') parser.json_config('--config', default='example.json') hparams = parser.parse_args() # hparams.learning_rate = 200 trials trial_generator = hparams.trials(2) Computes the trials needed for these experiments and serves them via a generator Example hparams = parser.parse_args() for trial_hparams in hparams.trials(2): # trial_hparams now has values sampled from the training routine optimize_parallel DEPRECATED... see optimize_parallel_gpu / _cpu hparams = parser.parse_args() hparams.optimize_parallel(function_to_optimize, nb_trials=20, nb_parallel=2) Parallelize the trials across nb_parallel processes. Arguments passed into the function_to_optimize are the trial_params and index of process it's in. Example # parallelize tuning on 2 gpus # this will place each trial in n into a given gpu def opt_function(trial_params, process_index): GPUs = ['0', '1'] os.environ[ CUDA_VISIBLE_DEVICES ] = GPUs[process_index] train_main(trial_params) hparams = parser.parse_args() hparams.optimize_parallel(opt_function, nb_trials=20, nb_parallel=2) # at the end of the optimize_parallel function, all 20 trials will be completed # in this case by running 10 sets of 2 trials in parallel optimize_parallel_gpu hparams = parser.parse_args() hparams.optimize_parallel_gpu(function_to_optimize, gpu_ids=['1', '0, 2'], nb_trials=20, nb_workers=2) Parallelize the trials across nb_workers processes. Auto assign the correct gpus. Argument passed into the function_to_optimize is the trial_params argument. Example # parallelize tuning on 2 gpus # this will place each trial in n into a given gpu def train_main(trial_params): # train your model, etc here... hparams = parser.parse_args() hparams.optimize_parallel_gpu(train_main, gpu_ids=['1', '0, 2'], nb_trials=20, nb_workers=2) # at the end of the optimize_parallel function, all 20 trials will be completed # in this case by running 10 sets of 2 trials in parallel optimize_parallel_cpu hparams = parser.parse_args() hparams.optimize_parallel_cpu(function_to_optimize, nb_trials=20, nb_workers=2) Parallelize the trials across nb_workers cpus. Argument passed into the function_to_optimize is the trial_params argument. Example # parallelize tuning on 2 cpus # this will place each trial in n into a given gpu def train_main(trial_params): # train your model, etc here... hparams = parser.parse_args() hparams.optimize_parallel_cpu(train_main, nb_trials=20, nb_workers=2) # at the end of the optimize_parallel function, all 20 trials will be completed # in this case by running 10 sets of 2 trials in parallel","title":"HyperOptArgumentParser class API"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#hyperoptargumentparser-class-api","text":"The HyperOptArgumentParser is a subclass of python's argparse , with added finctionality to change parameters on the fly as determined by a sampling strategy. You can instantiate an HyperOptArgumentParser via: from test_tube import HyperOptArgumentParser # subclass of argparse parser = HyperOptArgumentParser(strategy='random_search') parser.add_argument('--learning_rate', default=0.002, type=float, help='the learning rate') # let's enable optimizing over the number of layers in the network parser.opt_list('--nb_layers', default=2, type=int, tunable=True, options=[2, 4, 8]) # and tune the number of units in each layer parser.opt_range('--neurons', default=50, type=int, tunable=True, low=100, high=800, nb_samples=10) # compile (because it's argparse underneath) hparams = parser.parse_args() # run 20 trials of random search over the hyperparams for hparam_trial in hparams.trials(20): train_network(hparam_trial)","title":"HyperOptArgumentParser class API"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#init-options","text":"","title":"init options"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#strategy","text":"Use either random search or grid search for tuning: parser = HyperOptArgumentParser(strategy='grid_search')","title":"strategy"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#methods","text":"All the functionality from argparse works but we've added the following functionality:","title":"Methods"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#opt_list","text":"parser.opt_list('--nb_layers', default=2, type=int, tunable=True, options=[2, 4, 8]) Enables searching over a list of values for this parameter. The tunable values ONLY replace the argparse values when running a hyperparameter optimization search. This is on purpose so your code doesn't have to change when you want to tune it. Example parser.opt_list('--nb_layers', default=2, type=int, tunable=True, options=[2, 4, 8]) hparams = parser.parse_args() # hparams.nb_layers = 2 for trial in hparams.trials(2): # trial.nb_layers is now a value in [2, 4, 8] # but hparams.nb_layers is still 2","title":"opt_list"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#opt_range","text":"parser.opt_range('--neurons', default=50, type=int, tunable=True, low=100, high=800, nb_samples=8, log_base=None) Enables searching over a range of values chosen randomly using the nb_samples given. The tunable values only replace the argparse values when running a hyperparameter optimization search. This is on purpose so your code doesn't have to change when you want to tune it. If log_base is set to a positive number, it will randomly search over a log scale, where the log base is log_base . This is better for search over several orders of magnitude efficiently. Example parser.opt_range('--neurons', default=50, type=int, tunable=True, low=100, high=800, nb_samples=8) hparams = parser.parse_args() # hparams.neurons = 50 for trial in hparams.trials(2): # trial.nb_layers is now a value in [100, 200, 300, 400, 500, 600 700, 800] # but hparams.neurons is still 50","title":"opt_range"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#json_config","text":"parser.json_config('--config', default='example.json') Replaces default values in the parser with those read from the json file Example example.json { learning_rate : 200 } parser.add_argument('--learning_rate', default=0.002, type=float, help='the learning rate') parser.json_config('--config', default='example.json') hparams = parser.parse_args() # hparams.learning_rate = 200","title":"json_config"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#trials","text":"trial_generator = hparams.trials(2) Computes the trials needed for these experiments and serves them via a generator Example hparams = parser.parse_args() for trial_hparams in hparams.trials(2): # trial_hparams now has values sampled from the training routine","title":"trials"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#optimize_parallel","text":"DEPRECATED... see optimize_parallel_gpu / _cpu hparams = parser.parse_args() hparams.optimize_parallel(function_to_optimize, nb_trials=20, nb_parallel=2) Parallelize the trials across nb_parallel processes. Arguments passed into the function_to_optimize are the trial_params and index of process it's in. Example # parallelize tuning on 2 gpus # this will place each trial in n into a given gpu def opt_function(trial_params, process_index): GPUs = ['0', '1'] os.environ[ CUDA_VISIBLE_DEVICES ] = GPUs[process_index] train_main(trial_params) hparams = parser.parse_args() hparams.optimize_parallel(opt_function, nb_trials=20, nb_parallel=2) # at the end of the optimize_parallel function, all 20 trials will be completed # in this case by running 10 sets of 2 trials in parallel","title":"optimize_parallel"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#optimize_parallel_gpu","text":"hparams = parser.parse_args() hparams.optimize_parallel_gpu(function_to_optimize, gpu_ids=['1', '0, 2'], nb_trials=20, nb_workers=2) Parallelize the trials across nb_workers processes. Auto assign the correct gpus. Argument passed into the function_to_optimize is the trial_params argument. Example # parallelize tuning on 2 gpus # this will place each trial in n into a given gpu def train_main(trial_params): # train your model, etc here... hparams = parser.parse_args() hparams.optimize_parallel_gpu(train_main, gpu_ids=['1', '0, 2'], nb_trials=20, nb_workers=2) # at the end of the optimize_parallel function, all 20 trials will be completed # in this case by running 10 sets of 2 trials in parallel","title":"optimize_parallel_gpu"},{"location":"hyperparameter_optimization/HyperOptArgumentParser/#optimize_parallel_cpu","text":"hparams = parser.parse_args() hparams.optimize_parallel_cpu(function_to_optimize, nb_trials=20, nb_workers=2) Parallelize the trials across nb_workers cpus. Argument passed into the function_to_optimize is the trial_params argument. Example # parallelize tuning on 2 cpus # this will place each trial in n into a given gpu def train_main(trial_params): # train your model, etc here... hparams = parser.parse_args() hparams.optimize_parallel_cpu(train_main, nb_trials=20, nb_workers=2) # at the end of the optimize_parallel function, all 20 trials will be completed # in this case by running 10 sets of 2 trials in parallel","title":"optimize_parallel_cpu"}]}